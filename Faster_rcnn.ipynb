{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow numpy torch torchvision onnx onnxruntime==1.12.0 matplotlib opencv-python pycocotools"
      ],
      "metadata": {
        "id": "-HH5tcq7Egy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cyDV-218ELLz"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from onnx import numpy_helper\n",
        "import os\n",
        "import onnxruntime as rt\n",
        "from matplotlib.colors import hsv_to_rgb\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "def preprocess(image):\n",
        "    # Resize\n",
        "    ratio = 800.0 / min(image.size[0], image.size[1])\n",
        "    image = image.resize((int(ratio * image.size[0]), int(ratio * image.size[1])), Image.BILINEAR)\n",
        "\n",
        "    # Convert to BGR\n",
        "    image = np.array(image)[:, :, [2, 1, 0]].astype('float32')\n",
        "\n",
        "    # HWC -> CHW\n",
        "    image = np.transpose(image, [2, 0, 1])\n",
        "\n",
        "    # Normalize\n",
        "    mean_vec = np.array([102.9801, 115.9465, 122.7717])\n",
        "    for i in range(image.shape[0]):\n",
        "        image[i, :, :] = image[i, :, :] - mean_vec[i]\n",
        "\n",
        "    # Pad to be divisible of 32\n",
        "    import math\n",
        "    padded_h = int(math.ceil(image.shape[1] / 32) * 32)\n",
        "    padded_w = int(math.ceil(image.shape[2] / 32) * 32)\n",
        "\n",
        "    padded_image = np.zeros((3, padded_h, padded_w), dtype=np.float32)\n",
        "    padded_image[:, :image.shape[1], :image.shape[2]] = image\n",
        "    image = padded_image\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "# Start from ORT 1.10, ORT requires explicitly setting the providers parameter if you want to use execution providers\n",
        "# other than the default CPU provider (as opposed to the previous behavior of providers getting set/registered by default\n",
        "# based on the build flags) when instantiating InferenceSession.\n",
        "# For example, if NVIDIA GPU is available and ORT Python package is built with CUDA, then call API as following:\n",
        "# onnxruntime.InferenceSession(path/to/model, providers=['CUDAExecutionProvider'])\n",
        "os.system(\"wget https://github.com/AK391/models/raw/main/vision/object_detection_segmentation/faster-rcnn/model/FasterRCNN-10.onnx\")\n",
        "sess = rt.InferenceSession(\"FasterRCNN-10.onnx\")\n",
        "\n",
        "outputs = sess.get_outputs()\n",
        "\n",
        "\n",
        "classes = [\n",
        "    \"__background\",\n",
        "    \"person\",\n",
        "    \"bicycle\",\n",
        "    \"car\",\n",
        "    \"motorcycle\",\n",
        "    \"airplane\",\n",
        "    \"bus\",\n",
        "    \"train\",\n",
        "    \"truck\",\n",
        "    \"boat\",\n",
        "    \"traffic light\",\n",
        "    \"fire hydrant\",\n",
        "    \"stop sign\",\n",
        "    \"parking meter\",\n",
        "    \"bench\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"dog\",\n",
        "    \"horse\",\n",
        "    \"sheep\",\n",
        "    \"cow\",\n",
        "    \"elephant\",\n",
        "    \"bear\",\n",
        "    \"zebra\",\n",
        "    \"giraffe\",\n",
        "    \"backpack\",\n",
        "    \"umbrella\",\n",
        "    \"handbag\",\n",
        "    \"tie\",\n",
        "    \"suitcase\",\n",
        "    \"frisbee\",\n",
        "    \"skis\",\n",
        "    \"snowboard\",\n",
        "    \"sports ball\",\n",
        "    \"kite\",\n",
        "    \"baseball bat\",\n",
        "    \"baseball glove\",\n",
        "    \"skateboard\",\n",
        "    \"surfboard\",\n",
        "    \"tennis racket\",\n",
        "    \"bottle\",\n",
        "    \"wine glass\",\n",
        "    \"cup\",\n",
        "    \"fork\",\n",
        "    \"knife\",\n",
        "    \"spoon\",\n",
        "    \"bowl\",\n",
        "    \"banana\",\n",
        "    \"apple\",\n",
        "    \"sandwich\",\n",
        "    \"orange\",\n",
        "    \"broccoli\",\n",
        "    \"carrot\",\n",
        "    \"hot dog\",\n",
        "    \"pizza\",\n",
        "    \"donut\",\n",
        "    \"cake\",\n",
        "    \"chair\",\n",
        "    \"couch\",\n",
        "    \"potted plant\",\n",
        "    \"bed\",\n",
        "    \"dining table\",\n",
        "    \"toilet\",\n",
        "    \"tv\",\n",
        "    \"laptop\",\n",
        "    \"mouse\",\n",
        "    \"remote\",\n",
        "    \"keyboard\",\n",
        "    \"cell phone\",\n",
        "    \"microwave\",\n",
        "    \"oven\",\n",
        "    \"toaster\",\n",
        "    \"sink\",\n",
        "    \"refrigerator\",\n",
        "    \"book\",\n",
        "    \"clock\",\n",
        "    \"vase\",\n",
        "    \"scissors\",\n",
        "    \"teddy bear\",\n",
        "    \"hair drier\",\n",
        "    \"toothbrush\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "def display_objdetect_image(image, boxes, labels, scores, score_threshold=0.7):\n",
        "    # Resize boxes\n",
        "    ratio = 800.0 / min(image.size[0], image.size[1])\n",
        "    boxes /= ratio\n",
        "\n",
        "    _, ax = plt.subplots(1, figsize=(12,9))\n",
        "    image = np.array(image)\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Showing boxes with score > 0.7\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        if score > score_threshold:\n",
        "            rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=1, edgecolor='b', facecolor='none')\n",
        "            ax.annotate(classes[label] + ':' + str(np.round(score, 2)), (box[0], box[1]), color='w', fontsize=12)\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.savefig('out.png', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def inference(img):\n",
        "  input_image = Image.open(img)\n",
        "  orig_tensor = np.asarray(input_image)\n",
        "  input_tensor = preprocess(input_image)\n",
        "\n",
        "  output_names = list(map(lambda output: output.name, outputs))\n",
        "  input_name = sess.get_inputs()[0].name\n",
        "\n",
        "  boxes, labels, scores = sess.run(output_names, {input_name: input_tensor})\n",
        "  # display_objdetect_image(input_image, boxes, labels, scores)\n",
        "\n",
        "  return 'out.png'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "directory_path = \"/content/\"\n",
        "\n",
        "files = os.listdir(directory_path)\n",
        "results = []\n",
        "strt = time.time()\n",
        "count = 0\n",
        "for file in files:\n",
        "  if file.endswith(\".png\"):\n",
        "    count += 1\n",
        "    print(f\"{file} processed\")\n",
        "    result = inference(file)\n",
        "    results.append(result)\n",
        "end = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpgiO8eBF4bS",
        "outputId": "ccb61401-ebed-4a1d-abd7-4517288325f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1111.png processed\n",
            "908.png processed\n",
            "1357.png processed\n",
            "1138.png processed\n",
            "1187.png processed\n",
            "1251.png processed\n",
            "1123.png processed\n",
            "1287.png processed\n",
            "1058.png processed\n",
            "1069.png processed\n",
            "133.png processed\n",
            "1139.png processed\n",
            "1119.png processed\n",
            "1256.png processed\n",
            "1217.png processed\n",
            "1071.png processed\n",
            "1174.png processed\n",
            "1320.png processed\n",
            "1122.png processed\n",
            "1116.png processed\n",
            "1342.png processed\n",
            "999.png processed\n",
            "1195.png processed\n",
            "998.png processed\n",
            "1045.png processed\n",
            "1337.png processed\n",
            "1034.png processed\n",
            "1052.png processed\n",
            "1382.png processed\n",
            "1125.png processed\n",
            "12.png processed\n",
            "1280.png processed\n",
            "1048.png processed\n",
            "1101.png processed\n",
            "1352.png processed\n",
            "925.png processed\n",
            "1023.png processed\n",
            "1027.png processed\n",
            "1028.png processed\n",
            "1021.png processed\n",
            "1239.png processed\n",
            "1026.png processed\n",
            "1253.png processed\n",
            "127.png processed\n",
            "1176.png processed\n",
            "1065.png processed\n",
            "1015.png processed\n",
            "1137.png processed\n",
            "1133.png processed\n",
            "1158.png processed\n",
            "1344.png processed\n",
            "1040.png processed\n",
            "109.png processed\n",
            "1338.png processed\n",
            "1003.png processed\n",
            "1093.png processed\n",
            "954.png processed\n",
            "888.png processed\n",
            "921.png processed\n",
            "1081.png processed\n",
            "1315.png processed\n",
            "1014.png processed\n",
            "1245.png processed\n",
            "1145.png processed\n",
            "1300.png processed\n",
            "923.png processed\n",
            "1079.png processed\n",
            "1104.png processed\n",
            "1047.png processed\n",
            "1295.png processed\n",
            "118.png processed\n",
            "1333.png processed\n",
            "126.png processed\n",
            "1112.png processed\n",
            "1032.png processed\n",
            "1302.png processed\n",
            "1167.png processed\n",
            "1055.png processed\n",
            "1113.png processed\n",
            "1232.png processed\n",
            "1089.png processed\n",
            "1290.png processed\n",
            "1206.png processed\n",
            "1345.png processed\n",
            "1029.png processed\n",
            "1043.png processed\n",
            "124.png processed\n",
            "1281.png processed\n",
            "1269.png processed\n",
            "1339.png processed\n",
            "1186.png processed\n",
            "1160.png processed\n",
            "1278.png processed\n",
            "831.png processed\n",
            "110.png processed\n",
            "1310.png processed\n",
            "1154.png processed\n",
            "1207.png processed\n",
            "1329.png processed\n",
            "116.png processed\n",
            "1020.png processed\n",
            "1311.png processed\n",
            "1095.png processed\n",
            "1171.png processed\n",
            "1054.png processed\n",
            "1323.png processed\n",
            "1209.png processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Calulate total time of execution in sec and average time\n",
        "\n",
        "total_time = end - strt\n",
        "average_time = total_time / count\n",
        "\n",
        "print(\"Total time of execution:\", total_time, \"seconds\")\n",
        "print(\"Average time per image:\", average_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13YgKsAZGGEi",
        "outputId": "2bedf34d-5673-44a5-c56d-7cb19b8ad661"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time of execution: 703.7369585037231 seconds\n",
            "Average time per image: 6.576980920595544 seconds\n"
          ]
        }
      ]
    }
  ]
}